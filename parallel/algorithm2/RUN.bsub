#!/bin/bash
#BSUB -q hpcintro
#BSUB -n 24
# Number of processers allocated (in blocks) per compute node => 72 cores
#BSUB -R "span[block=24]"
#BSUB -W 3:00
#BSUB -R "select[model == XeonE5_2650v4]"
#BSUB -R "rusage[mem=10GB]"
#BSUB -J profiling
#BSUB -o out/Output_%J.out
#BSUB -e err/Error_%J.err

# Load modules
module purge
module load mpi/3.1.3-gcc-8.2.0

module load python3/3.6.2
source /zhome/56/0/117244/virtualenv/LSM/bin/activate

# Do not worry why this is here...
unset LSB_AFFINITY_HOSTFILE

# Loop number of instances
for ins in 20000 #40000 80000 160000 320000
do

# create files with python ins as input
#EXECUTABLE=Data/create_data.py		# name of the .py 
#python3 $EXECUTABLE $ins

# Loop number of features
# for feat in 200 400 800 1600 3200
for feat in 200 #400 800
do

# Loop number of processors
for np in 1 #2 4 8 16 24 32 40 48 56 64 72
do

# Loop poly_order
for poly in 2 3 4 5 6 7 8 9 10
#for poly in 2 4 8
do

# Loop Grank
#for Grank in 2 3 4 5 6 7 8 9 10
for Grank in 10
do

# Loop block size
for blocks in 1 #16 #48 192
do

out="result/ins${ins}_feat${feat}_proc${np}_poly${poly}_Grank${Grank}_blocks${blocks}"
out2="result_binding/ins${ins}_feat${feat}_proc${np}_poly${poly}_Grank${Grank}_blocks${blocks}_binding"
input="Data/feat_${feat}/poly_order_${poly}.txt Data/feat_${feat}/rank_${Grank}.txt Data/X_${ins}_${feat}.txt Data/y_${ins}.txt ${blocks}"

mpirun -np $np --mca rmaps_dist_device ib0 \
    --bind-to core --report-bindings \
    ./algorithm2 $input > $out 2>$out2

done #blocks
done #Grank
done #poly
done #np
done #feat
#rm -f Data/X_* Data/y_*
done #ins
